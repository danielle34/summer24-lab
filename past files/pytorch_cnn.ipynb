{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m dictionary_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/cslinxs/Desktop/all_weeks/summer24-lab/measurements_auscultatory_dictionary_ALL.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dictionary_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m---> 41\u001b[0m     all_auscultatory_dic \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# from utils import load_data, plot_history_torch, plot_heat_map\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "path_aurora_dataset = Path('/Users/cslinxs/Desktop/aurora_dataset/aurora_dataset/')\n",
    "\n",
    "\n",
    "def reject_outliers(data):\n",
    "    #return data[abs(data - np.mean(data)) < 0.3 * np.mean(data)]\n",
    "    return data[abs(data - np.mean(data)) <3 * np.std(data)]\n",
    "\n",
    "\n",
    "\n",
    "dictionary_path = \"/Users/cslinxs/Desktop/all_weeks/summer24-lab/measurements_auscultatory_dictionary_ALL.pkl\"\n",
    "\n",
    "with open(dictionary_path, 'rb') as handle:\n",
    "    all_auscultatory_dic = pickle.load(handle)\n",
    "\n",
    "# from utils import load_data, plot_history_torch, plot_heat_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aurora_dataset = Path('/Users/cslinxs/Desktop/aurora_dataset/aurora_dataset/')\n",
    "auscultatory_data = path_aurora_dataset / \"measurements_auscultatory.tsv\"\n",
    "\n",
    "participants_data =  path_aurora_dataset / \"participants.tsv\"\n",
    "basic_mesures_data = pd.read_csv(auscultatory_data,sep = '\\t').dropna(subset=[\"waveform_file_path\"]).dropna(subset=[\"sbp\"]).dropna(subset=[\"dbp\"]) \n",
    "\n",
    "def get_even_split(path):\n",
    "    #print(path)\n",
    "    df = pd.read_csv(path,sep = '\\t')   \n",
    "    pos_pressure = df[\"pressure\"]\n",
    "\n",
    "    neglist = [ -x for x in pos_pressure]\n",
    "\n",
    "    b, a = signal.butter(1, 0.002, analog=False)\n",
    "    gustafsson_avg = signal.filtfilt(b, a, x= pos_pressure, method=\"gust\")\n",
    "    y_flater = [real_pre-abs( guston_avg) for real_pre, guston_avg in zip(pos_pressure, gustafsson_avg)]\n",
    "\n",
    "    y_flater = np.array(y_flater)\n",
    "    neglist = [ -x for x in y_flater]\n",
    "\n",
    "    neg_max_values = max(neglist)\n",
    "    neg_mix_values = min(neglist)\n",
    "    mid_neg_value= neg_max_values - neg_mix_values\n",
    "\n",
    "    min_height = neg_max_values - mid_neg_value*0.30 \n",
    "\n",
    "    min_peaks, _ = find_peaks(neglist , height= min_height, width=80)\n",
    "\n",
    "\n",
    "    most_accurate_mins = min_peaks\n",
    "    diffrences_new_min = reject_outliers(np.diff(most_accurate_mins))\n",
    "    diffrences_new_min\n",
    "    # plt.plot(y_flater)\n",
    "    \n",
    "    # plt.show()\n",
    "    return  y_flater # (len(diffrences_new_min.mean()), pos_pressure)#len(diffrences_new_min.mean())\n",
    " \n",
    "\n",
    "def prepare_data_frame_for_lstm(df,n_steps,pos_pressure ):\n",
    "    df = df.pandas(df)\n",
    "    for i in range(1, n_steps+1):\n",
    "        df[f\"shift \\(t-{i})\"] = pos_pressure.shift(i)\n",
    "\n",
    "\n",
    "# everything[each_path] = [each_path_50_cords, filler_to_person[filler_to_person[\"waveform_file_path\"] == each_path][\"sbp\"], \n",
    "#                          filler_to_person[filler_to_person[\"waveform_file_path\"] == each_path][\"dbp\"] ]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "measurements_auscultatory/a000/a000.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a000/a000.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a001/a001.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a001/a001.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a002/a002.initial.Exercise_challenge_start_1.tsv\n",
      "hi\n",
      "measurements_auscultatory/a003/a003.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a003/a003.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a004/a004.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a004/a004.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a005/a005.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a005/a005.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a006/a006.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a006/a006.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a007/a007.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a007/a007.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a008/a008.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a008/a008.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a009/a009.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a009/a009.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a010/a010.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a010/a010.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a011/a011.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a011/a011.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a012/a012.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a012/a012.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a013/a013.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a013/a013.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a014/a014.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a014/a014.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a015/a015.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a015/a015.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a016/a016.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a016/a016.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a017/a017.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a017/a017.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a018/a018.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a018/a018.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a019/a019.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a019/a019.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a020/a020.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a020/a020.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a021/a021.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a021/a021.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a022/a022.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a022/a022.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a023/a023.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a023/a023.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a024/a024.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a024/a024.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a025/a025.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a025/a025.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a026/a026.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a026/a026.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a027/a027.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a027/a027.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a028/a028.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a028/a028.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a029/a029.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a029/a029.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a030/a030.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a030/a030.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a031/a031.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a031/a031.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a032/a032.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a032/a032.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a033/a033.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a033/a033.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a034/a034.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a034/a034.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a035/a035.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a035/a035.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a036/a036.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a036/a036.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a037/a037.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a037/a037.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a038/a038.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a038/a038.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a039/a039.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a039/a039.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a040/a040.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a040/a040.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a041/a041.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a041/a041.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a042/a042.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a042/a042.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a043/a043.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a043/a043.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a044/a044.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a044/a044.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a045/a045.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a045/a045.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a046/a046.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a046/a046.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a047/a047.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a047/a047.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a048/a048.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a048/a048.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a049/a049.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a049/a049.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a050/a050.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a050/a050.initial.Exercise_challenge_start_2.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "measurements_auscultatory/a051/a051.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a051/a051.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a052/a052.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a052/a052.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a053/a053.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a053/a053.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a054/a054.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a054/a054.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "measurements_auscultatory/a057/a057.initial.Exercise_challenge_start_1.tsv\n",
      "hi\n",
      "measurements_auscultatory/a058/a058.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a058/a058.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a059/a059.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a059/a059.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a060/a060.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a060/a060.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a061/a061.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a061/a061.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a062/a062.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a062/a062.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a063/a063.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a063/a063.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a064/a064.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a064/a064.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a065/a065.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a065/a065.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a066/a066.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a066/a066.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a067/a067.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a068/a068.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a068/a068.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a069/a069.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a069/a069.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a070/a070.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a070/a070.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a071/a071.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a071/a071.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a072/a072.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a072/a072.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a073/a073.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a073/a073.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a074/a074.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a074/a074.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a075/a075.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a075/a075.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a076/a076.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a076/a076.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a077/a077.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a077/a077.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a078/a078.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a078/a078.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a079/a079.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a079/a079.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a080/a080.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a080/a080.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a081/a081.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a081/a081.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a082/a082.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a082/a082.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a083/a083.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a083/a083.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a084/a084.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a084/a084.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a085/a085.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a085/a085.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a086/a086.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a086/a086.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a087/a087.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a087/a087.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a088/a088.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a088/a088.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a089/a089.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a089/a089.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a090/a090.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a090/a090.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a091/a091.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a091/a091.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a092/a092.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a092/a092.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a093/a093.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a093/a093.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a094/a094.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a094/a094.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a095/a095.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a095/a095.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a096/a096.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a096/a096.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a097/a097.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a097/a097.initial.Exercise_challenge_start_2.tsv\n",
      "hi\n",
      "measurements_auscultatory/a098/a098.initial.Exercise_challenge_start_1.tsv\n",
      "measurements_auscultatory/a098/a098.initial.Exercise_challenge_start_2.tsv\n"
     ]
    }
   ],
   "source": [
    "all_data_recordings = []\n",
    "\n",
    "for person in sorted(os.listdir(path_aurora_dataset/\"measurements_auscultatory\"))[:100]:\n",
    "    if \"a\" in person:\n",
    "        filler_to_person = basic_mesures_data[basic_mesures_data[\"pid\"] == person]\n",
    "        print(\"hi\")\n",
    "        for each_path in filler_to_person[\"waveform_file_path\"]:\n",
    "            if \"Exercise\" in each_path:\n",
    "                print(each_path)\n",
    "                flatlined_data = get_even_split(path_aurora_dataset/each_path)\n",
    "                all_data_recordings.append(flatlined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-4.81614166, -4.91633278, -5.016718  , ..., -8.04705951,\n",
      "       -8.04642814, -7.94611344]), array([ 3.22835535,  3.02848083,  2.92872685, ..., -4.53197234,\n",
      "       -4.63160368, -4.73141788]), array([-11.19155156, -11.39199536, -11.59288891, ..., -17.92033446,\n",
      "       -18.11889793, -18.31817672]), array([  6.00406163,   5.80429669,   5.6047609 , ..., -33.01579379,\n",
      "       -33.31315461, -33.61183061]), array([ 5.35659743,  4.95680496,  4.55720818, ..., -2.83950319,\n",
      "       -2.9392721 , -2.93915607]), array([-11.35453872, -11.75499094, -12.15590723, ..., -35.51649867,\n",
      "       -35.81366207, -36.11223935]), array([ 1.12953881,  4.72961894,  8.32988578, ..., 40.92741633,\n",
      "       45.4236966 , 49.92177015]), array([ 76.14760558,  75.75060787,  75.45660171, ..., -20.90291742,\n",
      "       -21.20123457, -21.50038871]), array([-27.15072646, -27.15179834, -27.15394216, ..., -12.2633743 ,\n",
      "       -12.36239525, -12.46190425]), array([-46.18580714, -46.2876315 , -46.39128325, ..., -17.27158362,\n",
      "       -17.57018746, -17.86948495]), array([ 21.89279803,  21.19365543,  20.49534954, ..., -19.18778096,\n",
      "       -19.48623746, -19.68546227]), array([35.24015588, 35.24154712, 35.14432869, ..., -0.84320687,\n",
      "       -0.8431403 , -0.84310701]), array([-51.41937069, -51.92140562, -52.42549035, ..., -33.75546298,\n",
      "       -34.05276146, -34.4514053 ]), array([-78.31641927, -78.81951607, -79.32572458, ...,  -7.79522841,\n",
      "        -7.99459126,  -8.19426973]), array([ 67.5601074 ,  68.06277954,  68.56813874, ..., -52.35237615,\n",
      "       -52.94817778, -53.54606975]), array([  5.80091402,   5.20113711,   4.60156554, ..., -20.22260893,\n",
      "       -20.52097584, -20.92015388]), array([ -2.66710169,  -2.96720995,  -3.36743633, ..., -27.19138707,\n",
      "       -27.68918997, -28.08808503]), array([-83.82121918, -81.32450369, -78.9309998 , ...,  17.5402375 ,\n",
      "        17.13889612,  16.73823136]), array([10.75008604, 10.15050452,  9.55132373, ..., -5.77687256,\n",
      "       -5.87640562, -5.97617067]), array([16.34869129, 17.14934461, 17.85067399, ..., -5.27860251,\n",
      "       -5.37817491, -5.47795963]), array([ 96.09225   , 100.896091  , 105.70391529, ..., -52.08964307,\n",
      "       -52.48548716, -52.88340332]), array([  9.31722752,   8.51758746,   7.71828367, ..., -20.07739187,\n",
      "       -20.17579589, -20.27499644]), array([-1.91251371, -1.91258922, -1.81273924, ..., -4.96413207,\n",
      "       -4.86375101, -4.76356196]), array([ 1.08950531,  0.78954536,  0.48961658, ..., 33.20910521,\n",
      "       32.80652676, 32.40524348]), array([ 8.27586077,  8.27618749,  8.27684095, ..., -8.23246561,\n",
      "       -8.53178309, -8.83143739]), array([-47.46209792, -46.86396576, -46.26768374, ...,  -7.42888817,\n",
      "        -7.62827994,  -7.82797288]), array([ 29.11097574,  28.91212304,  28.71441177, ..., -19.0825095 ,\n",
      "       -19.4809595 , -19.8801786 ]), array([ -2.29058539,  -2.69067977,  -3.19088136, ..., -16.36167951,\n",
      "       -17.16029695, -18.05959286]), array([16.51844909, 15.31908938, 14.12033446, ..., 21.8520344 ,\n",
      "       21.95029832, 22.04942882]), array([-21.26369401, -21.36453447, -21.56621936, ..., -14.44721182,\n",
      "       -14.6460495 , -14.84546539]), array([-40.38103719, -37.48260278, -34.68564913, ...,  -1.12678387,\n",
      "        -1.12669491,  -1.12665043]), array([-7.47690709, -7.57720326, -7.67779857, ..., -4.20830736,\n",
      "       -4.20797511, -4.20780899]), array([-2.24631239, -2.44640305, -2.5465893 , ...,  4.92918162,\n",
      "        4.82880726,  4.62862256]), array([26.01677836, 25.71780252, 25.41984199, ...,  0.06317902,\n",
      "       -0.53676084, -1.13672188]), array([14.23429123, 13.73484825, 13.3359485 , ..., -4.57884413,\n",
      "       -4.57848658, -4.47830879]), array([18.2678024 , 18.16852261, 18.06996009, ..., -5.65753083,\n",
      "       -5.8570664 , -5.95683222]), array([-14.91093169, -14.91152036, -15.01269871, ..., -15.43837303,\n",
      "       -15.43715417, -15.43654475]), array([ 82.36951908,  85.17279859,  88.07944163, ..., -10.05993837,\n",
      "       -10.55908591, -11.1586513 ]), array([ 15.40487263,  15.60548278,  15.80670901, ..., -18.85660972,\n",
      "       -19.45505585, -20.05427004]), array([ 27.95432503,  27.85542765,  27.75762998, ..., -13.78805434,\n",
      "       -13.98694801, -14.08639288]), array([-32.1912233 , -32.49249714, -32.79505376, ..., -10.21414361,\n",
      "       -10.81327207, -11.41282742]), array([ 3.1017357 ,  2.80185519,  2.60208629, ..., 29.86315826,\n",
      "       30.16076799, 30.45956844]), array([-17.9688506 , -16.26954322, -14.57087814, ...,  -7.11501985,\n",
      "        -7.21444331,  -7.41415258]), array([-18.51207898, -16.91279403, -15.41417776, ...,   3.35440888,\n",
      "         3.05417661,   2.75406492]), array([34.9092389 , 34.51061313, 34.2133508 , ..., 22.27887802,\n",
      "       21.87716252, 21.47631071]), array([16.15203564, 16.1526733 , 16.15394866, ..., -4.20916053,\n",
      "       -4.30881736, -4.4086443 ]), array([-4.27375261, -4.47392331, -4.67427063, ...,  9.98621411,\n",
      "        9.68545431,  9.48507788]), array([-2.14925842,  0.95068733,  4.05067061, ..., -3.48312536,\n",
      "       -3.48285037, -3.48271287]), array([154.89928873, 154.10539611, 153.21758645, ...,  14.90293188,\n",
      "        11.00217865,   7.10185979]), array([ -8.28944145,  -5.68974305,  -3.09026927, ..., -12.04850979,\n",
      "       -12.34752599, -12.64702966])]\n"
     ]
    }
   ],
   "source": [
    "print(all_data_recordings[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_auscultatory_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 218\u001b[0m\n\u001b[1;32m    214\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(y_test, y_pred)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 169\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m,  \u001b[38;5;66;03m# the random seed\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.3\u001b[39m,  \u001b[38;5;66;03m# the ratio of the test set\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m    164\u001b[0m }\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# X_train,y_train is the training set\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# X_test,y_test is the test set\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m auscultatory_pressure \u001b[38;5;241m=\u001b[39m[item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mall_auscultatory_dic\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    170\u001b[0m auscultatory_sbp \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m all_auscultatory_dic\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    171\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(auscultatory_pressure[:\u001b[38;5;241m50\u001b[39m],auscultatory_sbp[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m50\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_auscultatory_dic' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# project root path\n",
    "project_path = \"./\"\n",
    "# define log directory\n",
    "# must be a subdirectory of the directory specified when starting the web application\n",
    "# it is recommended to use the date time as the subdirectory name\n",
    "log_dir = project_path + \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = project_path + \"ecg_model.pt\"\n",
    "\n",
    "# the device to use\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "\n",
    "# define the dataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "# build the CNN model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # the first convolution layer, 4 21x1 convolution kernels, output shape (batch_size, 4, 300)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=21, stride=1, padding='same')\n",
    "        # the first pooling layer, max pooling, pooling size=3 , stride=2, output shape (batch_size, 4, 150)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        # the second convolution layer, 16 23x1 convolution kernels, output shape (batch_size, 16, 150)\n",
    "        self.conv2 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=23, stride=1, padding='same')\n",
    "        # the second pooling layer, max pooling, pooling size=3, stride=2, output shape (batch_size, 16, 75)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        # the third convolution layer, 32 25x1 convolution kernels, output shape (batch_size, 32, 75)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=25, stride=1, padding='same')\n",
    "        # the third pooling layer, average pooling, pooling size=3, stride=2, output shape (batch_size, 32, 38)\n",
    "        self.pool3 = nn.AvgPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        # the fourth convolution layer, 64 27x1 convolution kernels, output shape (batch_size, 64, 38)\n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=27, stride=1, padding='same')\n",
    "        # flatten layer, for the next fully connected layer, output shape (batch_size, 38*64)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # fully connected layer, 128 nodes, output shape (batch_size, 128)\n",
    "        self.fc1 = nn.Linear(64 * 38, 128)\n",
    "        # Dropout layer, dropout rate = 0.2\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # fully connected layer, 5 nodes (number of classes), output shape (batch_size, 5)\n",
    "        self.fc2 = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = (batch_size, 300)\n",
    "        # reshape the tensor with shape (batch_size, 300) to (batch_size, 1, 300)\n",
    "        x = x.reshape(-1, 1, 300)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# define the training function and validation function\n",
    "def train_steps(loop, model, criterion, optimizer):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    model.train()\n",
    "    for step_index, (X, y) in loop:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss = loss.item()\n",
    "        train_loss.append(loss)\n",
    "        pred_result = torch.argmax(pred, dim=1).detach().cpu().numpy()\n",
    "        y = y.detach().cpu().numpy()\n",
    "        acc = accuracy_score(y, pred_result)\n",
    "        train_acc.append(acc)\n",
    "        loop.set_postfix(loss=loss, acc=acc)\n",
    "    return {\"loss\": np.mean(train_loss),\n",
    "            \"acc\": np.mean(train_acc)}\n",
    "\n",
    "\n",
    "def test_steps(loop, model, criterion):\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step_index, (X, y) in loop:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y).item()\n",
    "\n",
    "            test_loss.append(loss)\n",
    "            pred_result = torch.argmax(pred, dim=1).detach().cpu().numpy()\n",
    "            y = y.detach().cpu().numpy()\n",
    "            acc = accuracy_score(y, pred_result)\n",
    "            test_acc.append(acc)\n",
    "            loop.set_postfix(loss=loss, acc=acc)\n",
    "    return {\"loss\": np.mean(test_loss),\n",
    "            \"acc\": np.mean(test_acc)}\n",
    "\n",
    "\n",
    "def train_epochs(train_dataloader, test_dataloader, model, criterion, optimizer, config, writer):\n",
    "    num_epochs = config['num_epochs']\n",
    "    train_loss_ls = []\n",
    "    train_loss_acc = []\n",
    "    test_loss_ls = []\n",
    "    test_loss_acc = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loop = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        test_loop = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "        train_loop.set_description(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "        test_loop.set_description(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
    "\n",
    "        train_metrix = train_steps(train_loop, model, criterion, optimizer)\n",
    "        test_metrix = test_steps(test_loop, model, criterion)\n",
    "\n",
    "        train_loss_ls.append(train_metrix['loss'])\n",
    "        train_loss_acc.append(train_metrix['acc'])\n",
    "        test_loss_ls.append(test_metrix['loss'])\n",
    "        test_loss_acc.append(test_metrix['acc'])\n",
    "\n",
    "        print(f'Epoch {epoch + 1}: '\n",
    "              f'train loss: {train_metrix[\"loss\"]}; '\n",
    "              f'train acc: {train_metrix[\"acc\"]}; ')\n",
    "        print(f'Epoch {epoch + 1}: '\n",
    "              f'test loss: {test_metrix[\"loss\"]}; '\n",
    "              f'test acc: {test_metrix[\"acc\"]}')\n",
    "\n",
    "        writer.add_scalar('train/loss', train_metrix['loss'], epoch)\n",
    "        writer.add_scalar('train/accuracy', train_metrix['acc'], epoch)\n",
    "        writer.add_scalar('validation/loss', test_metrix['loss'], epoch)\n",
    "        writer.add_scalar('validation/accuracy', test_metrix['acc'], epoch)\n",
    "\n",
    "    return {'train_loss': train_loss_ls,\n",
    "            'train_acc': train_loss_acc,\n",
    "            'test_loss': test_loss_ls,\n",
    "            'test_acc': test_loss_acc}\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = {\n",
    "        'seed': 42,  # the random seed\n",
    "        'test_ratio': 0.3,  # the ratio of the test set\n",
    "        'num_epochs': 30,\n",
    "        'batch_size': 128,\n",
    "        'lr': 0.001,\n",
    "    }\n",
    "\n",
    "    # X_train,y_train is the training set\n",
    "    # X_test,y_test is the test set\n",
    "\n",
    "    auscultatory_pressure =[item[0] for item in all_auscultatory_dic.values()]\n",
    "    auscultatory_sbp = [item[1] for item in all_auscultatory_dic.values()]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(auscultatory_pressure[:50],auscultatory_sbp[1][:50], test_size=0.3)\n",
    "    train_dataset, test_dataset = ECGDataset(X_train, y_train), ECGDataset(X_test, y_test)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "    # define the model\n",
    "    model = Model()\n",
    "    if os.path.exists(model_path):\n",
    "        # import the pre-trained model if it exists\n",
    "        print('Import the pre-trained model, skip the training process')\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "    else:\n",
    "        # build the CNN model\n",
    "        model = model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "        # print the model structure\n",
    "        summary(model, (config['batch_size'], X_train.shape[1]), col_names=[\"input_size\", \"kernel_size\", \"output_size\"],\n",
    "                verbose=2)\n",
    "\n",
    "        # define the Tensorboard SummaryWriter\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "        # train and evaluate model\n",
    "        history = train_epochs(train_dataloader, test_dataloader, model, criterion, optimizer, config, writer)\n",
    "        writer.close()\n",
    "        # save the model\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        # plot the training history\n",
    "        #plot_history_torch(history\n",
    "        plt.plot(history)\n",
    "\n",
    "    # predict the class of test data\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step_index, (X, y) in enumerate(test_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            pred_result = torch.argmax(pred, dim=1).detach().cpu().numpy()\n",
    "            y_pred.extend(pred_result)\n",
    "    # plot confusion matrix heat map\n",
    "    plt.plot(y_test, y_pred)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
