{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based off of someones code to analysis music type\n",
    "\n",
    "#https://github.com/Harbim001/Analysing_Nigerian_Music_Growth_Globally/blob/main/analysing_nigerian_music_growth_globally%20(1).py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dictionary_path = \"/Users/cslinxs/Desktop/all_weeks/summer24-lab/measurements_auscultatory_dictionary_ALL.pkl\"\n",
    "\n",
    "with open(dictionary_path, 'rb') as handle:\n",
    "    all_auscultatory_dic = pickle.load(handle)\n",
    "\n",
    "\n",
    "# Getting kid of ppl with bad averages , only 9 ppl with in dataset\n",
    "bad_keys = []\n",
    "for key, each_grouping in all_auscultatory_dic.items():\n",
    "    if True in list(np.isnan(each_grouping[0])):\n",
    "        bad_keys.append(key)\n",
    "print(len(bad_keys))\n",
    "\n",
    "for key in bad_keys:\n",
    "    del all_auscultatory_dic[key]\n",
    "\n",
    "\n",
    "\n",
    "#This groups ppl and would be usedful if I don't want overlaps in the people\n",
    "group_ppl = {}\n",
    "for key, each_grouping in list(all_auscultatory_dic.items()):\n",
    "    person_id = key.split(\"_\")[1].split(\"/\")[1]\n",
    "    # if person_id in list(people_htn):\n",
    "    if not(person_id in group_ppl):\n",
    "        group_ppl[person_id] = []\n",
    "    group_ppl[person_id].append({key: each_grouping})\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First im going to split ppl if they have hyper tension or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the person\n",
    "path_aurora_dataset = Path('/Users/cslinxs/Desktop/aurora_dataset/aurora_dataset/')\n",
    "\n",
    "# This is getting the PID of ppl with Hypertenstion\n",
    "participants_data =  path_aurora_dataset / \"participants.tsv\"\n",
    "participants_csv_data = pd.read_csv(participants_data,sep = '\\t')\n",
    "participants_csv_htn = participants_csv_data[participants_csv_data[\"self_report_htn\"].isin([\"managed\",\"unmanaged\"])]\n",
    "participants_csv_htn = participants_csv_htn[participants_csv_htn[\"pid\"].str.contains('a')]\n",
    "people_htn = participants_csv_htn[\"pid\"]\n",
    "people_htn\n",
    "\n",
    "\n",
    "def get_person_data(PID):\n",
    "    return ([([each_data[0] for each_data in item.values()]) for item in group_ppl[PID]], [([each_data[1] for each_data in item.values()][0]) for item in group_ppl[PID]], [item.keys() for item in group_ppl[PID]])\n",
    "\n",
    "# This groups people by a feature\n",
    "def get_person_data_group(diction, identifier):\n",
    "    return ([([each_data[0] for each_data in item.values()]) for item in diction[identifier]], [([each_data[1] for each_data in item.values()][0]) for item in diction[identifier]], [item.keys() for item in diction[identifier]])\n",
    "\n",
    "def get_person_split_data(dictionary_with_people):\n",
    "    return ([item[0] for item in dictionary_with_people],[item[1] for item in dictionary_with_people],[item[2] for item in dictionary_with_people])\n",
    "\n",
    "def get_people_with_hypertenstion():\n",
    "    hyperstion_people = []\n",
    "    non_hypertension_people = []\n",
    "    for key, each_grouping in list(all_auscultatory_dic.items()):\n",
    "        person_id = key.split(\"_\")[1].split(\"/\")[1]\n",
    "        if person_id in list(people_htn):\n",
    "            hyperstion_people.append(each_grouping)\n",
    "        else:\n",
    "            non_hypertension_people.append(each_grouping)\n",
    "            \n",
    "    return (hyperstion_people,non_hypertension_people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_with_hypertenstion = get_people_with_hypertenstion()[0]\n",
    "people_with_out_hypertenstion = get_people_with_hypertenstion()[1]\n",
    "\n",
    "# for now I will only test on people with hyptertension\n",
    "X = get_person_split_data(people_with_hypertenstion)[0]\n",
    "y = get_person_split_data(people_with_hypertenstion)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cslinxs/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0102 - loss: 5.4671 - val_accuracy: 0.0063 - val_loss: 5.1762\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0120 - loss: 5.1461 - val_accuracy: 0.0125 - val_loss: 5.1182\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0138 - loss: 5.0853 - val_accuracy: 0.0094 - val_loss: 5.1093\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0176 - loss: 5.0430 - val_accuracy: 0.0063 - val_loss: 5.1186\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0182 - loss: 5.0417 - val_accuracy: 0.0094 - val_loss: 5.1138\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0168 - loss: 5.0021 - val_accuracy: 0.0094 - val_loss: 5.1140\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0159 - loss: 5.0155 - val_accuracy: 0.0188 - val_loss: 5.1115\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0162 - loss: 5.0053 - val_accuracy: 0.0188 - val_loss: 5.1157\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0222 - loss: 4.9727 - val_accuracy: 0.0125 - val_loss: 5.1121\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0250 - loss: 4.9766 - val_accuracy: 0.0219 - val_loss: 5.1127\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0286 - loss: 4.9672 - val_accuracy: 0.0156 - val_loss: 5.1187\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0147 - loss: 4.9903 - val_accuracy: 0.0156 - val_loss: 5.1235\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0221 - loss: 4.9307 - val_accuracy: 0.0219 - val_loss: 5.1356\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0144 - loss: 4.9591 - val_accuracy: 0.0188 - val_loss: 5.1565\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0194 - loss: 4.9492 - val_accuracy: 0.0188 - val_loss: 5.1330\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0153 - loss: 4.9093 - val_accuracy: 0.0188 - val_loss: 5.1536\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0214 - loss: 4.9312 - val_accuracy: 0.0156 - val_loss: 5.1565\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0188 - loss: 4.9101 - val_accuracy: 0.0188 - val_loss: 5.1786\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0208 - loss: 4.9220 - val_accuracy: 0.0219 - val_loss: 5.1443\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0243 - loss: 4.8940 - val_accuracy: 0.0219 - val_loss: 5.1757\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0222 - loss: 4.8762 - val_accuracy: 0.0188 - val_loss: 5.1640\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0250 - loss: 4.8919 - val_accuracy: 0.0219 - val_loss: 5.1891\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0284 - loss: 4.8969 - val_accuracy: 0.0281 - val_loss: 5.1860\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0182 - loss: 4.8595 - val_accuracy: 0.0250 - val_loss: 5.1718\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0270 - loss: 4.8625 - val_accuracy: 0.0156 - val_loss: 5.2101\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0251 - loss: 4.8308 - val_accuracy: 0.0156 - val_loss: 5.1932\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0288 - loss: 4.8301 - val_accuracy: 0.0188 - val_loss: 5.2209\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0209 - loss: 4.8801 - val_accuracy: 0.0312 - val_loss: 5.2217\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0197 - loss: 4.8100 - val_accuracy: 0.0281 - val_loss: 5.2272\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0253 - loss: 4.8310 - val_accuracy: 0.0250 - val_loss: 5.2305\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0193 - loss: 4.8272 - val_accuracy: 0.0250 - val_loss: 5.2340\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0246 - loss: 4.8063 - val_accuracy: 0.0250 - val_loss: 5.2359\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0337 - loss: 4.7988 - val_accuracy: 0.0312 - val_loss: 5.2182\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0318 - loss: 4.8024 - val_accuracy: 0.0219 - val_loss: 5.2330\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0304 - loss: 4.8152 - val_accuracy: 0.0281 - val_loss: 5.2521\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0251 - loss: 4.8007 - val_accuracy: 0.0156 - val_loss: 5.2817\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0338 - loss: 4.7791 - val_accuracy: 0.0219 - val_loss: 5.2583\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0351 - loss: 4.7503 - val_accuracy: 0.0250 - val_loss: 5.2434\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0261 - loss: 4.7748 - val_accuracy: 0.0156 - val_loss: 5.3174\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0311 - loss: 4.7469 - val_accuracy: 0.0188 - val_loss: 5.3056\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0343 - loss: 4.7520 - val_accuracy: 0.0250 - val_loss: 5.3230\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0258 - loss: 4.7627 - val_accuracy: 0.0156 - val_loss: 5.3376\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0392 - loss: 4.7112 - val_accuracy: 0.0281 - val_loss: 5.3206\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0318 - loss: 4.6926 - val_accuracy: 0.0219 - val_loss: 5.3152\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0356 - loss: 4.6827 - val_accuracy: 0.0250 - val_loss: 5.3762\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0314 - loss: 4.6867 - val_accuracy: 0.0219 - val_loss: 5.3406\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0312 - loss: 4.6980 - val_accuracy: 0.0188 - val_loss: 5.3809\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0392 - loss: 4.6920 - val_accuracy: 0.0250 - val_loss: 5.3989\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0334 - loss: 4.6792 - val_accuracy: 0.0125 - val_loss: 5.3786\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0347 - loss: 4.6688 - val_accuracy: 0.0219 - val_loss: 5.3940\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0083 - loss: 5.4408     \n",
      "Test accuracy: 0.011264080181717873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature data using the same scaler used for the training data\n",
    "X_new = scaler.transform(new_data)\n",
    "\n",
    "# Reshape the input data for 1D CNN\n",
    "X_new = np.expand_dims(X_new, axis=2)\n",
    "\n",
    "# Predict the probabilities for each genre\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Get the genre index with the highest probability for each sample\n",
    "predicted_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode the genre indices to genre names\n",
    "predicted_genres = label_encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "# Add the predicted genres to the new dataset\n",
    "new_data['predicted_genre'] = predicted_genres\n",
    "\n",
    "print(new_data)\n",
    "\n",
    "print(tabulate(new_data.head(), headers='keys', tablefmt='pretty'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
